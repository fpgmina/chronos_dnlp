{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b5bfa9",
   "metadata": {
    "id": "06b5bfa9"
   },
   "source": [
    "# Chronos-2 SFT+LoRA — Evaluation Dump (window × ticker)\n",
    "\n",
    "This notebook **does not train** any model.\n",
    "\n",
    "It loads the checkpoints produced by `chronos2_sft_lora.ipynb` and runs an evaluation procedure consistent with `core/eval.py::evaluate_model_on_test`, **but additionally saves per-window, per-ticker results** to Parquet files.\n",
    "\n",
    "These dumps are then used by the companion notebook `chronos2_sft_lora_stats_tests.ipynb` to run paired statistical tests (ticker-level).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23a45ac",
   "metadata": {
    "id": "a23a45ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT: c:\\Users\\rosar\\chronos_dnlp\n",
      "DEVICE: cuda | CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Project imports\n",
    "current_dir = os.getcwd()\n",
    "REPO_ROOT = os.path.dirname(current_dir) # Using this notation to keep the rest of the code the same.\n",
    "sys.path.append(REPO_ROOT)\n",
    "\n",
    "\n",
    "from tiingo_data.download_data import get_daily_returns_data_cached\n",
    "from core.data import prepare_data_for_chronos\n",
    "from core.eval import evaluate_model_on_test\n",
    "from utils import get_device\n",
    "from chronos import Chronos2Pipeline\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"DEVICE:\", DEVICE, \"| CUDA:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93f9c87",
   "metadata": {
    "id": "e93f9c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2797, 114)\n",
      "Eval  shape: (1200, 114)\n",
      "Eval date range: 2021-02-12 00:00:00+00:00 → 2025-11-20 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Load data and evaluation split\n",
    "\n",
    "df_all = get_daily_returns_data_cached()\n",
    "df_train_clean, df_eval_clean = prepare_data_for_chronos(df_all, test_size=1200)\n",
    "\n",
    "print(\"Train shape:\", df_train_clean.shape)\n",
    "print(\"Eval  shape:\", df_eval_clean.shape)\n",
    "print(\"Eval date range:\", df_eval_clean.index.min(), \"→\", df_eval_clean.index.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91537a5",
   "metadata": {
    "id": "b91537a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HP global] {'prediction_length': 1, 'context_length': 128, 'num_steps': 1500, 'batch_size': 48, 'learning_rate': 3.113813151474403e-06, 'stride': 100, 'n_eval_samples': 100}\n"
     ]
    }
   ],
   "source": [
    "# Load best hyperparameters (tuning results)\n",
    "\n",
    "CSV_CANDIDATES = [\n",
    "    Path(REPO_ROOT) / \"notebooks\" / \"outputs\" / \"tuning_results\" / \"tuning_best_results.csv\",\n",
    "    Path(REPO_ROOT) / \"outputs\" / \"tuning_results\" / \"tuning_best_results.csv\"\n",
    "]\n",
    "best_csv_path = next((p for p in CSV_CANDIDATES if p.exists()), None)\n",
    "if best_csv_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"tuning_best_results.csv not found. Checked:\\n\" + \"\\n\".join(map(str, CSV_CANDIDATES))\n",
    "    )\n",
    "\n",
    "df_best = pd.read_csv(best_csv_path)\n",
    "df_best[\"group\"] = df_best[\"group\"].astype(str).str.strip()\n",
    "hp_by_group = df_best.set_index(\"group\").to_dict(orient=\"index\")\n",
    "\n",
    "PREDICTION_LENGTH = 1\n",
    "\n",
    "def get_hparams(group: str) -> dict:\n",
    "    g = str(group).strip()\n",
    "    if g not in hp_by_group:\n",
    "        raise KeyError(f\"Group '{g}' not found in tuning CSV. Available: {sorted(hp_by_group.keys())}\")\n",
    "    row = hp_by_group[g]\n",
    "    return dict(\n",
    "        prediction_length=PREDICTION_LENGTH,\n",
    "        context_length=int(row[\"context_length\"]),\n",
    "        num_steps=int(row[\"num_steps\"]),\n",
    "        batch_size=int(row[\"batch_size\"]),\n",
    "        learning_rate=float(row[\"learning_rate\"]),\n",
    "        stride=int(row.get(\"stride\", 50)),\n",
    "        n_eval_samples=int(row.get(\"n_eval_samples\", 100)),\n",
    "    )\n",
    "\n",
    "global_hp = get_hparams(\"global\")\n",
    "print(\"[HP global]\", global_hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3d48a8",
   "metadata": {
    "id": "4f3d48a8"
   },
   "outputs": [],
   "source": [
    "# Category definitions (GICS level 1)\n",
    "\n",
    "GICS_LEVEL_1 = {\n",
    "    \"Information Technology\": [\n",
    "        \"AAPL\", \"ADBE\", \"ADI\", \"AMD\", \"AMAT\", \"CSCO\", \"FIS\",\n",
    "        \"IBM\", \"INTC\", \"INTU\", \"LRCX\", \"MSFT\", \"MU\",\n",
    "        \"NVDA\", \"ORCL\", \"QCOM\", \"TXN\"\n",
    "    ],\n",
    "    \"Health Care\": [\n",
    "        \"ABBV\", \"ABT\", \"AMGN\", \"BDX\", \"BMY\", \"CVS\", \"DHR\",\n",
    "        \"ELV\", \"GILD\", \"HUM\", \"ISRG\", \"JNJ\",\n",
    "        \"LLY\", \"MRK\", \"PFE\", \"REGN\", \"SYK\", \"TMO\", \"VRTX\", \"ZTS\"\n",
    "    ],\n",
    "    \"Financials\": [\n",
    "        \"AIG\", \"AXP\", \"BAC\", \"BLK\", \"C\", \"CB\", \"CI\",\n",
    "        \"COF\", \"GS\", \"JPM\", \"MET\", \"MS\",\n",
    "        \"PNC\", \"PGR\", \"SCHW\", \"USB\", \"WFC\"\n",
    "    ],\n",
    "    \"Consumer Discretionary\": [\n",
    "        \"AMZN\", \"BKNG\", \"HD\", \"LOW\", \"MCD\",\n",
    "        \"META\", \"NFLX\", \"NKE\", \"SBUX\",\n",
    "        \"TGT\", \"TJX\"\n",
    "    ],\n",
    "    \"Consumer Staples\": [\n",
    "        \"CL\", \"COST\", \"EL\", \"KMB\", \"KO\",\n",
    "        \"MDLZ\", \"MO\", \"PEP\", \"PG\", \"PM\", \"WMT\"\n",
    "    ],\n",
    "    \"Industrials\": [\n",
    "        \"BA\", \"CAT\", \"CSX\", \"DE\", \"EMR\",\n",
    "        \"ETN\", \"FDX\", \"GD\", \"GE\", \"HON\",\n",
    "        \"ITW\", \"LMT\", \"MMM\", \"NSC\",\n",
    "        \"RTX\", \"UNP\", \"UPS\", \"WM\"\n",
    "    ],\n",
    "    \"Energy\": [\"COP\", \"CVX\", \"EOG\", \"OXY\", \"SLB\", \"XOM\"],\n",
    "    \"Communication Services\": [\"CMCSA\", \"CRM\", \"GOOG\", \"GOOGL\", \"T\", \"TMUS\", \"VZ\"],\n",
    "    \"Materials\": [\"APD\", \"LIN\", \"SHW\"],\n",
    "    \"Real Estate\": [\"AMT\", \"SPG\"],\n",
    "    \"Utilities\": [],\n",
    "}\n",
    "\n",
    "def slugify(category: str) -> str:\n",
    "    return (\n",
    "        category.lower()\n",
    "        .replace(\"&\", \"and\")\n",
    "        .replace(\"/\", \"_\")\n",
    "        .replace(\" \", \"_\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177a0415",
   "metadata": {
    "id": "177a0415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS_BASE: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\n",
      "LORA_ROOT: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\chronos2_sft_lora\n"
     ]
    }
   ],
   "source": [
    "# Locate checkpoints produced by the LoRA training notebook\n",
    "# We support both layouts:\n",
    "#   - running from repo root:        outputs/...\n",
    "#   - running from notebooks folder: notebooks/outputs/...\n",
    "# Choose the one that exists.\n",
    "cand1 = Path(REPO_ROOT) / \"notebooks\" / \"outputs\"\n",
    "cand2 = Path(REPO_ROOT) / \"outputs\"\n",
    "OUTPUTS_BASE = cand1 if cand1.exists() else cand2\n",
    "\n",
    "LORA_ROOT = OUTPUTS_BASE / \"chronos2_sft_lora\"\n",
    "general_ckpt = LORA_ROOT / \"general\" / \"finetuned-ckpt\"\n",
    "\n",
    "print(\"OUTPUTS_BASE:\", OUTPUTS_BASE)\n",
    "print(\"LORA_ROOT:\", LORA_ROOT)\n",
    "\n",
    "if not general_ckpt.exists():\n",
    "    raise FileNotFoundError(f\"LoRA general checkpoint not found: {general_ckpt}\")\n",
    "\n",
    "def category_ckpt(category: str) -> Path:\n",
    "    return LORA_ROOT / slugify(category) / \"finetuned-ckpt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376ad5bb",
   "metadata": {
    "id": "376ad5bb"
   },
   "outputs": [],
   "source": [
    "#  Metrics and window sampling (consistent with core/eval.py)\n",
    "\n",
    "QUANTILES = np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9], dtype=np.float32)\n",
    "\n",
    "def per_ticker_mql(y_true: np.ndarray, y_pred_quantiles: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Mean Quantile Loss (pinball) averaged over the 0.1..0.9 quantiles, per ticker.\n",
    "\n",
    "    Important: some Chronos configs may output more than 9 quantiles. To stay consistent with our\n",
    "    project evaluation (core/eval.py), we use the first 9 quantile columns (0.1..0.9) by index.\n",
    "    \"\"\"\n",
    "    y_pred_9 = y_pred_quantiles[:, :len(QUANTILES)]  # (N, 9)\n",
    "    errors = y_true[:, None] - y_pred_9              # (N, 9)\n",
    "    q = QUANTILES[None, :]                           # (1, 9)\n",
    "    pin = np.where(errors >= 0, q * errors, (q - 1.0) * errors)\n",
    "    return pin.mean(axis=1)\n",
    "\n",
    "def sample_start_indices(T: int, context_length: int, n_samples: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"Replicates the random window sampling used in core/eval.py::evaluate_model_on_test.\"\"\"\n",
    "    max_start = T - context_length - 1\n",
    "    if max_start <= 0:\n",
    "        raise ValueError(f\"Series too short: T={T}, context={context_length}\")\n",
    "    np.random.seed(seed)\n",
    "    n = min(n_samples, max_start)\n",
    "    return np.random.choice(np.arange(max_start), size=n, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5c73fc",
   "metadata": {
    "id": "dc5c73fc"
   },
   "outputs": [],
   "source": [
    "# Evaluation + dump (per window × ticker)\n",
    "\n",
    "def eval_dump_windows(\n",
    "    pipeline: Chronos2Pipeline,\n",
    "    df_test: pd.DataFrame,\n",
    "    context_length: int,\n",
    "    start_indices: np.ndarray,\n",
    "    model_name: str,\n",
    "    group_name: str,\n",
    "    out_path: Path,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Run a 1-step evaluation on sampled windows and save per-ticker results to Parquet.\"\"\"\n",
    "    data = df_test.values.astype(np.float32)  # shape (T, N)\n",
    "    T, N = data.shape\n",
    "    tickers = list(df_test.columns)\n",
    "    dates = df_test.index\n",
    "\n",
    "    rows = []\n",
    "    for w_id, start in enumerate(tqdm(start_indices, desc=f\"{model_name} | {group_name}\", leave=False)):\n",
    "        ctx = data[start:start+context_length, :].T        # (N, context)\n",
    "        y_true = data[start+context_length, :]             # (N,)\n",
    "        date = dates[start+context_length]\n",
    "\n",
    "        forecast = pipeline.predict([{\"target\": ctx}], prediction_length=1)\n",
    "        y_pred_q = forecast[0][:, :, 0].detach().cpu().numpy().astype(np.float32)  # (N, Q)\n",
    "        y_med = y_pred_q[:, 4]  # median by index (consistent with our project setup)\n",
    "\n",
    "        mae_t = np.abs(y_true - y_med)\n",
    "        mse_t = (y_true - y_med) ** 2\n",
    "        mql_t = per_ticker_mql(y_true, y_pred_q)\n",
    "\n",
    "        # Store a row per ticker (window × ticker granularity)\n",
    "        for i, tkr in enumerate(tickers):\n",
    "            rows.append({\n",
    "                \"window_id\": w_id,\n",
    "                \"start_idx\": int(start),\n",
    "                \"date\": date,\n",
    "                \"ticker\": tkr,\n",
    "                \"group\": group_name,\n",
    "                \"model\": model_name,\n",
    "                \"context_length\": int(context_length),\n",
    "                \"y_true\": float(y_true[i]),\n",
    "                \"y_pred_q10\": float(y_pred_q[i, 0]),\n",
    "                \"y_pred_q20\": float(y_pred_q[i, 1]),\n",
    "                \"y_pred_q30\": float(y_pred_q[i, 2]),\n",
    "                \"y_pred_q40\": float(y_pred_q[i, 3]),\n",
    "                \"y_pred_q50\": float(y_pred_q[i, 4]),\n",
    "                \"y_pred_q60\": float(y_pred_q[i, 5]),\n",
    "                \"y_pred_q70\": float(y_pred_q[i, 6]),\n",
    "                \"y_pred_q80\": float(y_pred_q[i, 7]),\n",
    "                \"y_pred_q90\": float(y_pred_q[i, 8]),\n",
    "                \"mae\": float(mae_t[i]),\n",
    "                \"mse\": float(mse_t[i]),\n",
    "                \"mql\": float(mql_t[i]),\n",
    "            })\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    df_out.to_parquet(out_path, index=False)\n",
    "    print(f\"Saved: {out_path}  (rows={len(df_out)})\")\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc232fef",
   "metadata": {
    "id": "cc232fef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline loaded.\n",
      "LoRA general loaded from: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\chronos2_sft_lora\\general\\finetuned-ckpt\n"
     ]
    }
   ],
   "source": [
    "# Load models (baseline + LoRA general)\n",
    "\n",
    "baseline = Chronos2Pipeline.from_pretrained(\"amazon/chronos-2\", device_map=DEVICE, dtype=torch.float32)\n",
    "lora_general = Chronos2Pipeline.from_pretrained(str(general_ckpt), device_map=DEVICE, dtype=torch.float32)\n",
    "\n",
    "print(\"Baseline loaded.\")\n",
    "print(\"LoRA general loaded from:\", general_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2545548",
   "metadata": {
    "id": "d2545548"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b351aa2fe494c709da3552c2b5db542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | global:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\global__baseline.parquet  (rows=11400)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4f06bfab4f4e359f8dc2c390b81eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | global:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\global__lora_general.parquet  (rows=11400)\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL dumps\n",
    "\n",
    "DUMPS_DIR = OUTPUTS_BASE / \"eval_dumps\" / \"sft_lora\"\n",
    "DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ctx_g = global_hp[\"context_length\"]\n",
    "n_g = global_hp[\"n_eval_samples\"]\n",
    "starts_g = sample_start_indices(len(df_eval_clean), ctx_g, n_g, seed=42)\n",
    "\n",
    "global_baseline_path = DUMPS_DIR / \"global__baseline.parquet\"\n",
    "global_lora_path = DUMPS_DIR / \"global__lora_general.parquet\"\n",
    "\n",
    "_ = eval_dump_windows(baseline, df_eval_clean, ctx_g, starts_g, \"baseline\", \"global\", global_baseline_path)\n",
    "_ = eval_dump_windows(lora_general, df_eval_clean, ctx_g, starts_g, \"lora_general\", \"global\", global_lora_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a191f67",
   "metadata": {
    "id": "9a191f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running core/eval.py evaluation (global) ...\n",
      "\n",
      "CORE baseline: {'mean_quantile_loss': np.float32(0.0073292092), 'mean_mse': np.float32(0.0005467396), 'mean_mae': np.float32(0.016542953)}\n",
      "DUMP baseline: {'mean_mql': 0.007329209622847358, 'mean_mae': 0.01654295417169985, 'mean_mse': 0.0005467396141380736}\n",
      "\n",
      "CORE lora   : {'mean_quantile_loss': np.float32(0.006323756), 'mean_mse': np.float32(0.0004593847), 'mean_mae': np.float32(0.014547602)}\n",
      "DUMP lora   : {'mean_mql': 0.006323756255968188, 'mean_mae': 0.014547601015714973, 'mean_mse': 0.0004593847257632555}\n",
      "\n",
      "Note: core reports mean_quantile_loss; dump reports mean_mql (same concept, computed per ticker).\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: aggregated metrics vs core/eval.py (global)\n",
    "\n",
    "def agg_dump_metrics(parquet_path: Path) -> dict:\n",
    "    d = pd.read_parquet(parquet_path)\n",
    "    return {\n",
    "        \"mean_mql\": float(d[\"mql\"].mean()),\n",
    "        \"mean_mae\": float(d[\"mae\"].mean()),\n",
    "        \"mean_mse\": float(d[\"mse\"].mean()),\n",
    "    }\n",
    "\n",
    "print(\"Running core/eval.py evaluation (global) ...\")\n",
    "core_base = evaluate_model_on_test(baseline, df_eval_clean, context_length=ctx_g, n_samples=n_g)\n",
    "core_lora = evaluate_model_on_test(lora_general, df_eval_clean, context_length=ctx_g, n_samples=n_g)\n",
    "\n",
    "dump_base = agg_dump_metrics(global_baseline_path)\n",
    "dump_lora = agg_dump_metrics(global_lora_path)\n",
    "\n",
    "print(\"\\nCORE baseline:\", {k: core_base[k] for k in [\"mean_quantile_loss\",\"mean_mse\",\"mean_mae\"]})\n",
    "print(\"DUMP baseline:\", dump_base)\n",
    "\n",
    "print(\"\\nCORE lora   :\", {k: core_lora[k] for k in [\"mean_quantile_loss\",\"mean_mse\",\"mean_mae\"]})\n",
    "print(\"DUMP lora   :\", dump_lora)\n",
    "\n",
    "print(\"\\nNote: core reports mean_quantile_loss; dump reports mean_mql (same concept, computed per ticker).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa5461f",
   "metadata": {
    "id": "9fa5461f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories with available tickers: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab9a1c7a7b549999c5a3bd73161cd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | information_technology:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\information_technology__baseline.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62b97bfec244d588fa7768acc6d7cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | information_technology:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\information_technology__lora_general_ctx_global.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f83a6b131b845ecb2d7f990b92dab70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | information_technology:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\information_technology__lora_general_ctx_cat.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b45dce3aa04498492fe5b181716fec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | information_technology:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\information_technology__lora_category.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea0ca1158dc4962b00c077ae860f709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | health_care:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\health_care__baseline.parquet  (rows=900)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dc439932ae4f948053fd4d95209b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | health_care:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\health_care__lora_general_ctx_global.parquet  (rows=900)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961b0c2669604dcab7cc1de4a2d1cdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | health_care:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\health_care__lora_general_ctx_cat.parquet  (rows=900)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46a658b64044504b7069da78866e896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | health_care:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\health_care__lora_category.parquet  (rows=900)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa90b6a2f9942f4b9e402bcf56ae8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | financials:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\financials__baseline.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d1d7c8163c484981d24b50cf823fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | financials:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\financials__lora_general_ctx_global.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac4c1a9ea784db6826811a6f9ec2487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | financials:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\financials__lora_general_ctx_cat.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72464a42e22345838a066a2104b5349d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | financials:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\financials__lora_category.parquet  (rows=1700)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f31dd77fb54e63ad64d66c240c6671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | consumer_discretionary:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_discretionary__baseline.parquet  (rows=2000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6128525af228446dab75634d70c4eff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | consumer_discretionary:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_discretionary__lora_general_ctx_global.parquet  (rows=2000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8b3d1644e94a37b578cdee584f3fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | consumer_discretionary:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_discretionary__lora_general_ctx_cat.parquet  (rows=2000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a917f96b4a0e4c918763052e287f9551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | consumer_discretionary:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_discretionary__lora_category.parquet  (rows=2000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec45daa9e11c49ff800cd507002b17d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | consumer_staples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_staples__baseline.parquet  (rows=1100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e86d06b30d4fb4a9f95f4908dd953f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | consumer_staples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_staples__lora_general_ctx_global.parquet  (rows=1100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267f1bf49bd8466c9f28a3e81d312b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | consumer_staples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_staples__lora_general_ctx_cat.parquet  (rows=1100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa6b575ee894ebcb1900da04f5fb539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | consumer_staples:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\consumer_staples__lora_category.parquet  (rows=1100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4779ff8ae249648eb551ddd5071c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | industrials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\industrials__baseline.parquet  (rows=3600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd08152be2d04a329808d0b1550134e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | industrials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\industrials__lora_general_ctx_global.parquet  (rows=3600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090800bcf3154d02aa2401b2ea6e8475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | industrials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\industrials__lora_general_ctx_cat.parquet  (rows=3600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7b2b46388e4b5b97e6c2ac11c85372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | industrials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\industrials__lora_category.parquet  (rows=3600)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7ee3f32f5c4bde803e286077dc576c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | energy:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\energy__baseline.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe611a6cafb4480daa56d1c88d4526ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | energy:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\energy__lora_general_ctx_global.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae615d6aa404fa9a4893efad4c8ddb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | energy:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\energy__lora_general_ctx_cat.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c106e21911b444f3a89d8d104ef2187a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | energy:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\energy__lora_category.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7f36f41bc341d6bbb7d0104c62e72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | communication_services:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\communication_services__baseline.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffc6b8cda1841e7b3e8745ba1085824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | communication_services:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\communication_services__lora_general_ctx_global.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630ae97533f54e6ead9a67df6a3710cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | communication_services:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\communication_services__lora_general_ctx_cat.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816017ac53904e1589b66a2c88d55a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | communication_services:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\communication_services__lora_category.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68a268dff5f464182af2bf4cf9e47b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | materials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\materials__baseline.parquet  (rows=400)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca64bcd12484c4885957f983a872f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | materials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\materials__lora_general_ctx_global.parquet  (rows=400)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019ad4159e64448a95cc7d2a72ddbfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | materials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\materials__lora_general_ctx_cat.parquet  (rows=400)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f0d012851b412db8c614200e248316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | materials:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\materials__lora_category.parquet  (rows=400)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25fde57b61d4c9e93e2b4d217b6ae66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "baseline | real_estate:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\real_estate__baseline.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2f14fd04484630825314776fe8f062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | real_estate:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\real_estate__lora_general_ctx_global.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8cb8ed2da84146899bbdf6d8d41cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_general | real_estate:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\real_estate__lora_general_ctx_cat.parquet  (rows=300)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767042ab6d6848eb817756246e712f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lora_category | real_estate:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\\real_estate__lora_category.parquet  (rows=300)\n",
      "Done. Dumps saved to: c:\\Users\\rosar\\chronos_dnlp\\notebooks\\outputs\\eval_dumps\\sft_lora\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY dumps\n",
    "# For each category, we dump:\n",
    "#  - baseline (context = category context)\n",
    "#  - LoRA general evaluated with global context (replicates the training notebook's choice)\n",
    "#  - LoRA general evaluated with category context (fair paired comparison)\n",
    "#  - LoRA category model (context = category context)\n",
    "cats = []\n",
    "for category, tickers in GICS_LEVEL_1.items():\n",
    "    avail = [t for t in tickers if t in df_eval_clean.columns]\n",
    "    if len(avail) > 0:\n",
    "        cats.append((category, avail))\n",
    "\n",
    "print(\"Categories with available tickers:\", len(cats))\n",
    "\n",
    "for category, tickers in cats:\n",
    "    # Hyperparameters\n",
    "    try:\n",
    "        cat_hp = get_hparams(category)\n",
    "    except KeyError:\n",
    "        print(f\"[{category}] skip: no tuned hyperparameters found in CSV.\")\n",
    "        continue\n",
    "\n",
    "    df_cat = df_eval_clean[tickers]\n",
    "    ctx_cat = cat_hp[\"context_length\"]\n",
    "    n_cat = cat_hp[\"n_eval_samples\"]\n",
    "    starts_cat = sample_start_indices(len(df_cat), ctx_cat, n_cat, seed=42)\n",
    "\n",
    "    # Load category checkpoint if available\n",
    "    ckpt = category_ckpt(category)\n",
    "    if not ckpt.exists():\n",
    "        print(f\"[{category}] skip: checkpoint not found at {ckpt}\")\n",
    "        continue\n",
    "\n",
    "    lora_cat = Chronos2Pipeline.from_pretrained(str(ckpt), device_map=DEVICE, dtype=torch.float32)\n",
    "\n",
    "    slug = slugify(category)\n",
    "\n",
    "    p_base = DUMPS_DIR / f\"{slug}__baseline.parquet\"\n",
    "    p_cat  = DUMPS_DIR / f\"{slug}__lora_category.parquet\"\n",
    "    p_gen_globalctx = DUMPS_DIR / f\"{slug}__lora_general_ctx_global.parquet\"\n",
    "    p_gen_catctx    = DUMPS_DIR / f\"{slug}__lora_general_ctx_cat.parquet\"\n",
    "\n",
    "    #  Baseline (category context)\n",
    "    _ = eval_dump_windows(baseline, df_cat, ctx_cat, starts_cat, \"baseline\", slug, p_base)\n",
    "\n",
    "    #  General LoRA (global context, as in training notebook category evaluation)\n",
    "    ctx_global = global_hp[\"context_length\"]\n",
    "    starts_globalctx = sample_start_indices(len(df_cat), ctx_global, n_cat, seed=42)\n",
    "    _ = eval_dump_windows(lora_general, df_cat, ctx_global, starts_globalctx, \"lora_general\", slug, p_gen_globalctx)\n",
    "\n",
    "    #  General LoRA (category context, fair paired)\n",
    "    _ = eval_dump_windows(lora_general, df_cat, ctx_cat, starts_cat, \"lora_general\", slug, p_gen_catctx)\n",
    "\n",
    "    #  Category LoRA (category context)\n",
    "    _ = eval_dump_windows(lora_cat, df_cat, ctx_cat, starts_cat, \"lora_category\", slug, p_cat)\n",
    "\n",
    "    # Clean up GPU memory between categories\n",
    "    del lora_cat\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Done. Dumps saved to:\", DUMPS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "H100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "chronos_dnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
